{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing of MaxQuant output (proteinGroups.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy import logical_or\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: Path to tab-sep text document\n",
    "Output: Pandas dataframe\n",
    "\"\"\"\n",
    "def load_df(file):\n",
    "    df = pd.read_csv(file, sep='\\t', lineterminator='\\r', dtype={\"Only identified by site\": str, \"Reverse\": str})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data\n",
    "* Remove rows corresponding to the proteins only identified by site/Reverse/Potential contaminant\n",
    "* Remove rows with multiple protein IDs\n",
    "* Extract separately the LFQ and the iBAQ quantification info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: Dataframe (assumes columns 'Only identified by site', 'Reverse', 'Potential contaminant')\n",
    "Output: Dataframe with rows having a '+' in any of these columns removed\n",
    "\"\"\"\n",
    "def clean_weakly_identified(df):\n",
    "    df = df[(df['Only identified by site'] != '+') & (df.Reverse != '+') & (df['Potential contaminant'] != '+')]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: Dataframe\n",
    "Output: Dataframe where rows containing multiple protein IDs have been removed\n",
    "\"\"\"\n",
    "def remove_dup_proteinIDs(df):\n",
    "    single_proteinID = df['Majority protein IDs'].str.contains(';') == False\n",
    "    df = df[single_proteinID]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: Dataframe, string\n",
    "Output: Dataframe filtered to contain the protein ID column and columns containing the input string\n",
    "\"\"\"\n",
    "\n",
    "def slice_by_column(df, col_name):\n",
    "    selected_col_name = col_name + \".*|Majority protein IDs\"\n",
    "    df_slice = df.filter(regex = selected_col_name)\n",
    "    return df_slice\n",
    "\n",
    "### Take separate df slices for different quant techniques\n",
    "LFQ_df = slice_by_column(df, 'LFQ')\n",
    "#print(\"***** LFQ_df:\\n\", LFQ_df.head())\n",
    "\n",
    "iBAQ_df = slice_by_column(df, 'iBAQ ') \n",
    "#print(\"\\n***** iBAQ_df:\\n\", iBAQ_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize\n",
    "### For both LFQ and iBAQ:\n",
    "* Consider only the proteins observed at least in 50 percent of the sample for at least one organ for quantification\n",
    "* log2 normalize\n",
    "* Median normalize: the median of the log2(LFQ or IBAQ) of each protein in a given sample is used to normalize all the protein abundance of this sample, then multiply all the resulting values by the median of the medians\n",
    "* Impute the missing values: the minimum of the resulting table divided by 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Filter out proteins where quant value is 0 for >= 50% of samples for all organs\n",
    "#\n",
    "#########################\n",
    "\"\"\"\n",
    "Input: dataframe, list of names of groups (as strings) by which to sort column names\n",
    "Output: filtered dataframe\n",
    "\"\"\"\n",
    "def filter_low_observed(df, groups, organ_columns, organ_counts):\n",
    "    samples_per_group = 6  # TODO dynamically assign variable\n",
    "    threshold = samples_per_group/2\n",
    "    df_cols = df.columns.values.tolist()\n",
    "    \n",
    "    for group in groups:\n",
    "        regex = re.compile(r'.*' + group)\n",
    "        organ_columns[group] = list(filter(regex.search, df_cols))\n",
    "        cols = organ_columns[group] # Get corresponding list of column names\n",
    "        organ_counts[group] = (iBAQ_df[cols] > 0).sum(1) # count number of samples with non-zero abundance for each protein\n",
    "        \n",
    "    conditions = list(organ_counts[g] >= threshold for g in groups)\n",
    "    df = df[logical_or.reduce(conditions)]\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Unnormalized data abundances \n",
    "#\n",
    "#########################\n",
    "\n",
    "default_dimensions = (10, 6)\n",
    "base_dir = 'D:\\\\Images\\\\' ### TODO take as input\n",
    "\n",
    "### TODO: dynamically order columns\n",
    "# Group columns by organ so x-axis will be sorted accordingly\n",
    "#iBAQ_df = iBAQ_df[['Majority protein IDs'] + organ_columns['Brain'] + organ_columns['Heart'] + organ_columns['Kidney'] + organ_columns['Liver'] + organ_columns['Lung']]\n",
    "\n",
    "def make_boxplot(df, title, dimensions = default_dimensions):\n",
    "    df.boxplot(return_type='axes', figsize = dimensions)\n",
    "    plt.xticks(rotation='vertical')\n",
    "    output_path = base_dir + title + '.pdf'\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kush494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4451: RuntimeWarning: divide by zero encountered in log2\n",
      "  return lib.map_infer(x.asobject, func)\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#\n",
    "# log2 normalize\n",
    "#\n",
    "#########################\n",
    "\n",
    "def log2_normalize(df):\n",
    "    df.iloc[:,1:] = df.iloc[:,1:].applymap(np.log2)\n",
    "    # log2(0) returns -inf; replace with NaN to avoid skewing data\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "log2_normalize(iBAQ_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Map organs to colors for visualization clarity \n",
    "#\n",
    "#########################\n",
    "\"\"\"\n",
    "Input: none\n",
    "Output: Dict mapping columns to colors based on organ/group\n",
    "\"\"\"\n",
    "def map_colors(sample_groups, organ_columns):\n",
    "    color_dict = {} # Column name : color\n",
    "    num_colors = 6\n",
    "    colors = sns.color_palette(\"hls\", num_colors)\n",
    "    color = 0\n",
    "\n",
    "    for organ in sample_groups:\n",
    "        cols = organ_columns[organ] # Get the list of column names for the organ\n",
    "        for col in cols:\n",
    "            color_dict[col] = colors[color % len(colors)]\n",
    "        color += 1\n",
    "        \n",
    "    return color_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# log2 transformed distribution \n",
    "#\n",
    "#########################\n",
    "\n",
    "#make_boxplot(iBAQ_df, 'TESTING')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_seaborn_boxplot(df, title, colors = color_dict, dimensions = default_dimensions):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = dimensions)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation = 90)\n",
    "    sns.boxplot(data = df, palette = color_dict, ax = ax)\n",
    "    output_path = base_dir + title + '.pdf'\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Median normalize\n",
    "#\n",
    "#########################\n",
    "\n",
    "def median_normalize(df):\n",
    "    quants = df.iloc[:,1:] # Split off iBAQ columns to process\n",
    "    median_of_medians = quants.median().median()\n",
    "    quants /= quants.median(axis=0) # divide each value by sample median\n",
    "    quants *= median_of_medians # multiply each value by median of medians\n",
    "\n",
    "    df.iloc[:,1:] = quants # insert processed iBAQ values into original df\n",
    "    print(iBAQ_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Median normalized log2 data distribution \n",
    "#\n",
    "#########################\n",
    "\n",
    "#make_boxplot(iBAQ_df, 'Median Normalized Boxplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_seaborn_boxplot(iBAQ_df, 'Median Normalized Boxplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Impute missing values\n",
    "#\n",
    "#########################\n",
    "\n",
    "def impute_missing(df):\n",
    "    df_min = df.iloc[:,1:].min().min()\n",
    "    impute_val = df_min/2\n",
    "    df = df.fillna(impute_val)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Perform PCA on the data\n",
    "#\n",
    "#########################\n",
    "\n",
    "\"\"\"\n",
    "Input: unindexed dataframe (first column will become index)\n",
    "Output: tuple (PCA object, PCA coordinates for dataframe)\n",
    "\"\"\"\n",
    "def do_pca(df):\n",
    "\n",
    "    df.set_index('Majority protein IDs', inplace=True)\n",
    "    scaled_data = preprocessing.scale(df.T)\n",
    "\n",
    "    pca = PCA() # create a PCA object\n",
    "    pca.fit(scaled_data) # do the math\n",
    "    pca_data = pca.transform(scaled_data) # get PCA coordinates for dataframe\n",
    "    \n",
    "    return(pca, pca_data)\n",
    "    \n",
    "#########################\n",
    "#\n",
    "# Draw a scree plot \n",
    "#\n",
    "#########################\n",
    "\n",
    "def make_scree_plot(pca, pca_data, title):\n",
    "\n",
    "    per_var = np.round(pca.explained_variance_ratio_* 100, decimals = 1)\n",
    "    labels = ['PC' + str(x) for x in range(1, len(per_var)+1)]\n",
    " \n",
    "    plt.bar(x = range(1, len(per_var) + 1), height = per_var, tick_label = labels)\n",
    "    plt.ylabel('Percentage of Explained Variance')\n",
    "    plt.xlabel('Principal Component')\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xticks(rotation='vertical')\n",
    "    output_path = base_dir + title + '.pdf'\n",
    "\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "#make_scree_plot(pca, pca_data, 'Scree Plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Draw PCA Graph \n",
    "#\n",
    "#########################\n",
    "\n",
    "def draw_pca_graph(df, pca_data, title):\n",
    "    \n",
    "    pca_df = pd.DataFrame(pca_data, index = [df.columns.values.tolist()], columns = labels)\n",
    " \n",
    "    plt.title('PCA Graph')\n",
    "    plt.xlabel('PC1 - {0}%'.format(per_var[0]))\n",
    "    plt.ylabel('PC2 - {0}%'.format(per_var[1]))\n",
    " \n",
    "    for column in pca_df.index:\n",
    "        plt.scatter(pca_df.PC1.loc[column], pca_df.PC2.loc[column], color = color_dict[column])\n",
    "        plt.annotate(column, (pca_df.PC1.loc[column], pca_df.PC2.loc[column]), color = color_dict[column])\n",
    "\n",
    "    output_path = base_dir + title + '.pdf'\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\")\n",
    "    \n",
    "# draw_pca_graph(iBAQ_df, pca_data, 'PCA Graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Determine which proteins had the biggest influence on PC1 \n",
    "#\n",
    "#########################\n",
    "\n",
    "def top_n_loading_scores(pca, df, n):\n",
    "    \n",
    "    loading_scores = pd.Series(pca.components_[0], index = df.index)\n",
    "    sorted_loading_scores = loading_scores.abs().sort_values(ascending = False)\n",
    "\n",
    "    top_proteins = sorted_loading_scores[0:n].index.values\n",
    "    return loading_scores[top_proteins]\n",
    "\n",
    "#print(top_n_loading_scores(pca, iBAQ_df, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmaps\n",
    "* Pearson Correlations\n",
    "* Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Pearson correlation of the samples compared to each other \n",
    "#\n",
    "#########################\n",
    "\n",
    "def make_pearson_matrix(df, title, colormap = \"RdBu_r\", dimensions = (16, 11)):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = dimensions)\n",
    "    ax.set_title('Pearson Correlations', size = 20)\n",
    "\n",
    "    corr = df.corr(method = 'pearson')\n",
    "    sns.heatmap(corr, \n",
    "                xticklabels = corr.columns.values,\n",
    "                yticklabels = corr.columns.values,\n",
    "                annot = True, # Show numerical values in each box\n",
    "                cmap = colormap, \n",
    "                ax = ax) \n",
    "    \n",
    "    output_path = base_dir + title + '.pdf'\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\")\n",
    "    \n",
    "#make_pearson_matrix(iBAQ_df, 'Pearson Correlations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Hierarchical clustering of proteins\n",
    "#\n",
    "#########################\n",
    "\n",
    "def hierarchical_cluster(df, title, dimensions = (10, 6)):\n",
    "\n",
    "    z = linkage(iBAQ_df.values, method='ward')\n",
    "\n",
    "    plt.figure(figsize = dimensions)\n",
    "    plt.title('Hierarchical Clustering of Proteins')\n",
    "    plt.ylabel('distance')\n",
    "    dendrogram(z,\n",
    "               leaf_rotation=90.,  # rotates the x axis labels\n",
    "               #leaf_font_size=8.,  # font size for the x axis labels\n",
    "              )\n",
    "    \n",
    "    output_path = base_dir + title + '.pdf'\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\")\n",
    "\n",
    "#hierarchical_cluster(iBAQ_df, 'Hierarchical Clustering')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA and t-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_proteins_by_anova(df, pval):\n",
    "    # Build list of proteins that pass ANOVA\n",
    "    pass_anova = []\n",
    "    max_pval = pval\n",
    "    proteins = list(df.index)\n",
    "\n",
    "    # Perform ANOVA on each row (protein) grouping by organ\n",
    "    # If the protein passes ANOVA (p-value <= max_pval), add it to the list of proteins to keep\n",
    "    for i in range(len(df)): \n",
    "        f, p = stats.f_oneway(df.iloc[i, :6],\n",
    "                              df.iloc[i, 6:12],\n",
    "                              df.iloc[i, 12:18], \n",
    "                              df.iloc[i, 18:24], \n",
    "                              df.iloc[i, 24:30])\n",
    "        if p <= max_pval:\n",
    "            pass_anova.append(proteins[i])\n",
    "\n",
    "    # Filter dataframe down to only include proteins in pass_anova\n",
    "    pass_anova_df = df[df.index.isin(pass_anova)]\n",
    "    return pass_anova_df\n",
    "\n",
    "#pass_anova_df = filter_proteins_by_anova(iBAQ_df, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Heatmap of proteins\n",
    "#\n",
    "#########################\n",
    "\n",
    "def protein_heatmap(df, title, colormap = \"RdBu_r\"):\n",
    "\n",
    "    sns.clustermap(df,\n",
    "                   method = 'ward',\n",
    "                   z_score = 1, # on columns\n",
    "                   cmap = colormap)\n",
    "\n",
    "    output_path = base_dir + title + '.pdf'\n",
    "    plt.savefig(output_path, bbox_inches = \"tight\")\n",
    "    \n",
    "#protein_heatmap(pass_anova_df, 'BRING THE HEAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Tukey Test\n",
    "#\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Full Pipeline \n",
    "#\n",
    "#########################\n",
    "\"\"\"\n",
    "Runs a spreadsheet through the process of cleaning and analyzing, producing charts\n",
    "\n",
    "Input: path to proteinGroupt.txt file, list of group names (e.g. ['Brain', 'Lung' ...]), directory for images\n",
    "Output: Final dataframe for more exploration. Images will be saved into image_dir\n",
    "\"\"\"\n",
    "def mq_pipeline(file, groups, image_dir):\n",
    "    default_dimensions = (10, 6)\n",
    "    df = load_df(file)\n",
    "    df = clean_weakly_identified(df)\n",
    "    df = remove_dup_proteinIDs(df)\n",
    "    \n",
    "    print(df.shape)\n",
    "        \n",
    "    iBAQ_df = slice_by_column(df, 'iBAQ ') \n",
    "    LFQ_df = slice_by_column(df, 'LFQ') \n",
    "    \n",
    "    organ_columns = {} # 'Liver': ['iBAQ 04_Liver', 'iBAQ 05_Liver', ...]\n",
    "    organ_counts = {} # 'Liver': \n",
    "    \n",
    "    iBAQ_df = filter_low_observed(iBAQ_df, groups, organ_columns, organ_counts)\n",
    "    make_boxplot(iBAQ_df, 'Unnormalized Protein Abundances')\n",
    "    \n",
    "    ### TODO: dynamically order columns\n",
    "    # Group columns by organ so x-axis will be sorted accordingly\n",
    "    iBAQ_df = iBAQ_df[['Majority protein IDs'] + organ_columns['Brain'] + organ_columns['Heart'] + organ_columns['Kidney'] + organ_columns['Liver'] + organ_columns['Lung']]\n",
    "    \n",
    "    ### Normalize and produce box plots\n",
    "    log2_normalize(iBAQ_df)\n",
    "    color_dict = map_colors(groups, organ_columns)\n",
    "    make_seaborn_boxplot(iBAQ_df, 'Log2 Transformed Boxplot')\n",
    "    median_normalize(iBAQ_df)\n",
    "    make_seaborn_boxplot(iBAQ_df, 'Median Normalized Boxplot')\n",
    "    \n",
    "    imputed_iBAQ_df = impute_missing(iBAQ_df)\n",
    "    pca, pca_data = do_pca(imputed_iBAQ_df)\n",
    "    \n",
    "    make_scree_plot(pca, pca_data, 'Scree Plot') \n",
    "    draw_pca_graph(imputed_iBAQ_df, pca_data, 'PCA Graph')\n",
    "    make_pearson_matrix(imputed_iBAQ_df, 'Pearson Correlations')\n",
    "    hierarchical_cluster(imputed_iBAQ_df, 'Hierarchical Clustering')\n",
    "    \n",
    "    ### Note: pass_anova_df still has imputed values\n",
    "    pass_anova_df = filter_proteins_by_anova(imputed_iBAQ_df, 0.05)\n",
    "    protein_heatmap(pass_anova_df, 'Proteins Passing ANOVA Heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5530, 294)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Item wrong length 5692 instead of 5530.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-406-ff0da5ce2576>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D:\\\\Images\\\\PipelineTest'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmq_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_groups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-405-46629c98728b>\u001b[0m in \u001b[0;36mmq_pipeline\u001b[1;34m(file, groups, image_dir)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0morgan_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;31m# 'Liver':\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0miBAQ_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_low_observed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miBAQ_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morgan_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morgan_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mmake_boxplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miBAQ_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Unnormalized Protein Abundances'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-385-6a5908566bd5>\u001b[0m in \u001b[0;36mfilter_low_observed\u001b[1;34m(df, groups, organ_columns, organ_counts)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mconditions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morgan_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconditions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1956\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1957\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1958\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1959\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1993\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1994\u001b[0m                 raise ValueError('Item wrong length %d instead of %d.' %\n\u001b[1;32m-> 1995\u001b[1;33m                                  (len(key), len(self.index)))\n\u001b[0m\u001b[0;32m   1996\u001b[0m             \u001b[1;31m# check_bool_indexer will throw exception if Series key cannot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m             \u001b[1;31m# be reindexed to match DataFrame rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Item wrong length 5692 instead of 5530."
     ]
    }
   ],
   "source": [
    "datafile = \"D:\\proteinGroupsCleaned.txt\"\n",
    "sample_groups = ['Brain', 'Heart', 'Kidney', 'Liver', 'Lung']\n",
    "base_dir = 'D:\\\\Images\\\\PipelineTest'\n",
    "\n",
    "mq_pipeline(datafile, sample_groups, base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO \n",
    "* Dynamically determine column indices for organ groups, size of groups; order columns\n",
    "* Take argument to choose iBAQ or LFQ? Or just do both\n",
    "* Write images out to file - take arguments for base directory and specific dataset name\n",
    "* Pipeline combining all functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
