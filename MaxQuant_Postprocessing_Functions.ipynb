{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing of MaxQuant output (proteinGroups.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy import logical_or\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: Path to tab-sep text document\n",
    "Output: Pandas dataframe\n",
    "\"\"\"\n",
    "def load_df(file):\n",
    "    df = pd.read_csv(file, sep='\\t', lineterminator='\\r', dtype={\"Only identified by site\": str, \"Reverse\": str, \"Potential contaminant\": str})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data\n",
    "* Remove rows corresponding to the proteins only identified by site/Reverse/Potential contaminant\n",
    "* Remove rows with multiple protein IDs\n",
    "* Extract separately the LFQ and the iBAQ quantification info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: Dataframe (assumes columns 'Only identified by site', 'Reverse', 'Potential contaminant')\n",
    "Output: Dataframe with rows having a '+' in any of these columns removed\n",
    "\"\"\"\n",
    "def clean_weakly_identified(df):\n",
    "    df = df[(df['Only identified by site'] != '+') & (df.Reverse != '+') & (df['Potential contaminant'] != '+')]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: Dataframe\n",
    "Output: Dataframe where rows containing multiple protein IDs have been removed\n",
    "\"\"\"\n",
    "def remove_dup_proteinIDs(df):\n",
    "    single_proteinID = df['Majority protein IDs'].str.contains(';') == False\n",
    "    df = df[single_proteinID]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: Dataframe, string\n",
    "Output: Dataframe filtered to contain the protein ID column and columns containing the input string\n",
    "\"\"\"\n",
    "\n",
    "def slice_by_column(df, col_name):\n",
    "    selected_col_name = col_name + \".*|Majority protein IDs\"\n",
    "    df_slice = df.filter(regex = selected_col_name)\n",
    "    return df_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize\n",
    "### For both LFQ and iBAQ:\n",
    "* Consider only the proteins observed at least in 50 percent of the sample for at least one organ for quantification\n",
    "* log2 normalize\n",
    "* Median normalize: the median of the log2(LFQ or IBAQ) of each protein in a given sample is used to normalize all the protein abundance of this sample, then multiply all the resulting values by the median of the medians\n",
    "* Impute the missing values: the minimum of the resulting table divided by 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Filter out proteins where quant value is 0 for >= 50% of samples for all organs\n",
    "#\n",
    "#########################\n",
    "\"\"\"\n",
    "Input: dataframe, list of names of groups (as strings) by which to sort column names\n",
    "Output: filtered dataframe\n",
    "\"\"\"\n",
    "def filter_low_observed(df, groups, organ_columns, organ_counts):\n",
    "    samples_per_group = 6  # TODO dynamically assign variable\n",
    "    threshold = samples_per_group/2\n",
    "    df_cols = df.columns.values.tolist()\n",
    "    \n",
    "    for group in groups:\n",
    "        regex = re.compile(r'.*' + group)\n",
    "        organ_columns[group] = list(filter(regex.search, df_cols))\n",
    "        cols = organ_columns[group] # Get corresponding list of column names\n",
    "        organ_counts[group] = (df[cols] > 0).sum(1) # count number of samples with non-zero abundance for each protein\n",
    "        \n",
    "    conditions = list(organ_counts[g] >= threshold for g in groups)\n",
    "    df = df[logical_or.reduce(conditions)]\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Unnormalized data abundances \n",
    "#\n",
    "#########################\n",
    "\n",
    "### TODO: dynamically order columns\n",
    "# Group columns by organ so x-axis will be sorted accordingly\n",
    "#iBAQ_df = iBAQ_df[['Majority protein IDs'] + organ_columns['Brain'] + organ_columns['Heart'] + organ_columns['Kidney'] + organ_columns['Liver'] + organ_columns['Lung']]\n",
    "\n",
    "def make_boxplot(df, title, dimensions = default_dimensions):\n",
    "    df.boxplot(return_type='axes', figsize = dimensions)\n",
    "    plt.xticks(rotation='vertical')\n",
    "    output_path = base_dir + title + '.pdf'\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# log2 normalize\n",
    "#\n",
    "#########################\n",
    "\n",
    "def log2_normalize(df):\n",
    "    df.iloc[:,1:] = df.iloc[:,1:].applymap(np.log2)\n",
    "    # log2(0) returns -inf; replace with NaN to avoid skewing data\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Map organs to colors for visualization clarity \n",
    "#\n",
    "#########################\n",
    "\"\"\"\n",
    "Input: List of strings, dict\n",
    "Output: Dict mapping columns to colors based on organ/group\n",
    "\"\"\"\n",
    "def map_colors(groups, organ_columns):\n",
    "    color_dict = {} # Column name : color\n",
    "    num_colors = 6\n",
    "    colors = sns.color_palette(\"hls\", num_colors)\n",
    "    color = 0\n",
    "\n",
    "    for organ in groups:\n",
    "        cols = organ_columns[organ] # Get the list of column names for the organ\n",
    "        for col in cols:\n",
    "            color_dict[col] = colors[color % len(colors)]\n",
    "        color += 1\n",
    "        \n",
    "    return color_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_seaborn_boxplot(df, title, colors = color_dict, dimensions = default_dimensions):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = dimensions)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation = 90)\n",
    "    sns.boxplot(data = df, palette = colors, ax = ax)\n",
    "    output_path = base_dir + title + '.pdf'\n",
    "    plt.savefig(output_path, bbox_inches = \"tight\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Median normalize\n",
    "#\n",
    "#########################\n",
    "\n",
    "def median_normalize(df):\n",
    "    quants = df.iloc[:,1:] # Split off iBAQ columns to process\n",
    "    median_of_medians = quants.median().median()\n",
    "    quants /= quants.median(axis = 0) # divide each value by sample median\n",
    "    quants *= median_of_medians # multiply each value by median of medians\n",
    "\n",
    "    df.iloc[:,1:] = quants # insert processed iBAQ values into original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Impute missing values\n",
    "#\n",
    "#########################\n",
    "\n",
    "def impute_missing(df):\n",
    "    df_min = df.iloc[:,1:].min().min()\n",
    "    impute_val = df_min/2\n",
    "    df = df.fillna(impute_val)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Perform PCA on the data\n",
    "#\n",
    "#########################\n",
    "\n",
    "\"\"\"\n",
    "Input: unindexed dataframe (first column will become index)\n",
    "Output: tuple (PCA object, PCA coordinates for dataframe)\n",
    "\"\"\"\n",
    "def do_pca(df):\n",
    "\n",
    "    df.set_index('Majority protein IDs', inplace=True)\n",
    "    scaled_data = preprocessing.scale(df.T)\n",
    "\n",
    "    pca = PCA() # create a PCA object\n",
    "    pca.fit(scaled_data) # do the math\n",
    "    pca_data = pca.transform(scaled_data) # get PCA coordinates for dataframe\n",
    "    \n",
    "    return(pca, pca_data)\n",
    "    \n",
    "#########################\n",
    "#\n",
    "# Draw a scree plot \n",
    "#\n",
    "#########################\n",
    "\n",
    "def make_scree_plot(pca, pca_data, title):\n",
    "\n",
    "    per_var = np.round(pca.explained_variance_ratio_* 100, decimals = 1)\n",
    "    labels = ['PC' + str(x) for x in range(1, len(per_var)+1)]\n",
    " \n",
    "    plt.bar(x = range(1, len(per_var) + 1), height = per_var, tick_label = labels)\n",
    "    plt.ylabel('Percentage of Explained Variance')\n",
    "    plt.xlabel('Principal Component')\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xticks(rotation='vertical')\n",
    "    output_path = base_dir + title + '.pdf'\n",
    "\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Draw PCA Graph \n",
    "#\n",
    "#########################\n",
    "\n",
    "def draw_pca_graph(df, pca_data, title, color_dict):\n",
    "    \n",
    "    pca_df = pd.DataFrame(pca_data, index = [df.columns.values.tolist()], columns = labels)\n",
    " \n",
    "    plt.title('PCA Graph')\n",
    "    plt.xlabel('PC1 - {0}%'.format(per_var[0]))\n",
    "    plt.ylabel('PC2 - {0}%'.format(per_var[1]))\n",
    " \n",
    "    for column in pca_df.index:\n",
    "        plt.scatter(pca_df.PC1.loc[column], pca_df.PC2.loc[column], color = color_dict[column])\n",
    "        plt.annotate(column, (pca_df.PC1.loc[column], pca_df.PC2.loc[column]), color = color_dict[column])\n",
    "\n",
    "    output_path = base_dir + title + '.pdf'\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Determine which proteins had the biggest influence on PC1 \n",
    "#\n",
    "#########################\n",
    "\n",
    "def top_n_loading_scores(pca, df, n):\n",
    "    \n",
    "    loading_scores = pd.Series(pca.components_[0], index = df.index)\n",
    "    sorted_loading_scores = loading_scores.abs().sort_values(ascending = False)\n",
    "\n",
    "    top_proteins = sorted_loading_scores[0:n].index.values\n",
    "    return loading_scores[top_proteins]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmaps\n",
    "* Pearson Correlations\n",
    "* Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Pearson correlation of the samples compared to each other \n",
    "#\n",
    "#########################\n",
    "\n",
    "def make_pearson_matrix(df, title, colormap = \"RdBu_r\", dimensions = (16, 11)):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = dimensions)\n",
    "    ax.set_title('Pearson Correlations', size = 20)\n",
    "\n",
    "    corr = df.corr(method = 'pearson')\n",
    "    sns.heatmap(corr, \n",
    "                xticklabels = corr.columns.values,\n",
    "                yticklabels = corr.columns.values,\n",
    "                annot = True, # Show numerical values in each box\n",
    "                cmap = colormap, \n",
    "                ax = ax) \n",
    "    \n",
    "    output_path = base_dir + title + '.pdf'\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Hierarchical clustering of proteins\n",
    "#\n",
    "#########################\n",
    "\n",
    "def hierarchical_cluster(df, title, dimensions = (10, 6)):\n",
    "\n",
    "    z = linkage(df.values, method='ward')\n",
    "\n",
    "    plt.figure(figsize = dimensions)\n",
    "    plt.title('Hierarchical Clustering of Proteins')\n",
    "    plt.ylabel('distance')\n",
    "    dendrogram(z,\n",
    "               leaf_rotation=90.,  # rotates the x axis labels\n",
    "               #leaf_font_size=8.,  # font size for the x axis labels\n",
    "              )\n",
    "    \n",
    "    output_path = base_dir + title + '.pdf'\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA and t-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_proteins_by_anova(df, pval):\n",
    "    # Build list of proteins that pass ANOVA\n",
    "    pass_anova = []\n",
    "    max_pval = pval\n",
    "    proteins = list(df.index)\n",
    "\n",
    "    # Perform ANOVA on each row (protein) grouping by organ\n",
    "    # If the protein passes ANOVA (p-value <= max_pval), add it to the list of proteins to keep\n",
    "    for i in range(len(df)): \n",
    "        f, p = stats.f_oneway(df.iloc[i, :6],\n",
    "                              df.iloc[i, 6:12],\n",
    "                              df.iloc[i, 12:18], \n",
    "                              df.iloc[i, 18:24], \n",
    "                              df.iloc[i, 24:30])\n",
    "        if p <= max_pval:\n",
    "            pass_anova.append(proteins[i])\n",
    "\n",
    "    # Filter dataframe down to only include proteins in pass_anova\n",
    "    pass_anova_df = df[df.index.isin(pass_anova)]\n",
    "    return pass_anova_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Heatmap of proteins\n",
    "#\n",
    "#########################\n",
    "\n",
    "def protein_heatmap(df, title, colormap = \"RdBu_r\"):\n",
    "\n",
    "    sns.clustermap(df,\n",
    "                   method = 'ward',\n",
    "                   z_score = 1, # on columns\n",
    "                   cmap = colormap)\n",
    "\n",
    "    output_path = base_dir + title + '.pdf'\n",
    "    plt.savefig(output_path, bbox_inches = \"tight\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Tukey Test\n",
    "#\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Full Pipeline \n",
    "#\n",
    "#########################\n",
    "\"\"\"\n",
    "Runs a spreadsheet through the process of cleaning and analyzing, producing charts\n",
    "\n",
    "Input: path to proteinGroupt.txt file, list of group names (e.g. ['Brain', 'Lung' ...]), directory for images\n",
    "Output: Log2 and median normalized dataframe (missing values not imputed). Images will be saved into image_dir\n",
    "\"\"\"\n",
    "def mq_pipeline(file, groups, image_dir):\n",
    "    default_dimensions = (10, 6)\n",
    "    df = load_df(file)\n",
    "    df = clean_weakly_identified(df)\n",
    "    df = remove_dup_proteinIDs(df)\n",
    "        \n",
    "    iBAQ_df = slice_by_column(df, 'iBAQ ') \n",
    "    #LFQ_df = slice_by_column(df, 'LFQ') \n",
    "    \n",
    "    organ_columns = {} # 'Liver': ['iBAQ 04_Liver', 'iBAQ 05_Liver', ...]\n",
    "    organ_counts = {} # 'Liver': \n",
    "    \n",
    "    iBAQ_df = filter_low_observed(iBAQ_df, groups, organ_columns, organ_counts)\n",
    "    make_boxplot(iBAQ_df, 'Unnormalized Protein Abundances')\n",
    "    \n",
    "    ### TODO: dynamically order columns\n",
    "    # Group columns by organ so x-axis will be sorted accordingly\n",
    "    iBAQ_df = iBAQ_df[['Majority protein IDs'] + organ_columns['Brain'] + organ_columns['Heart'] + organ_columns['Kidney'] + organ_columns['Liver'] + organ_columns['Lung']]\n",
    "    \n",
    "    ### Normalize and produce box plots\n",
    "    log2_normalize(iBAQ_df)\n",
    "    color_dict = map_colors(groups, organ_columns)\n",
    "    make_seaborn_boxplot(iBAQ_df, 'Log2 Transformed Boxplot', color_dict)\n",
    "    median_normalize(iBAQ_df)\n",
    "    make_seaborn_boxplot(iBAQ_df, 'Median Normalized Boxplot', color_dict)\n",
    "    \n",
    "    ### PCA\n",
    "    imputed_iBAQ_df = impute_missing(iBAQ_df.copy())\n",
    "    pca, pca_data = do_pca(imputed_iBAQ_df)\n",
    "    \n",
    "    make_scree_plot(pca, pca_data, 'Scree Plot') \n",
    "    draw_pca_graph(imputed_iBAQ_df, pca_data, 'PCA Graph', color_dict)\n",
    "    make_pearson_matrix(imputed_iBAQ_df, 'Pearson Correlations')\n",
    "    hierarchical_cluster(imputed_iBAQ_df, 'Hierarchical Clustering')\n",
    "    \n",
    "    ### Note: pass_anova_df still has imputed values\n",
    "    pval = 0.05\n",
    "    pass_anova_df = filter_proteins_by_anova(imputed_iBAQ_df, pval)\n",
    "    protein_heatmap(pass_anova_df, 'Proteins Passing ANOVA Heatmap')\n",
    "    \n",
    "    return iBAQ_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kush494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4451: RuntimeWarning: divide by zero encountered in log2\n",
      "  return lib.map_infer(x.asobject, func)\n",
      "C:\\Users\\kush494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:523: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Majority protein IDs  iBAQ Adult_07_Brain  iBAQ Adult_08_Brain  \\\n",
      "0          1433B_MOUSE            28.802652            29.167231   \n",
      "1          1433E_MOUSE            29.687798            29.775015   \n",
      "2          1433F_MOUSE            28.890100            28.473655   \n",
      "3          1433G_MOUSE            30.189062            29.799795   \n",
      "4          1433S_MOUSE            28.429346            28.365577   \n",
      "\n",
      "   iBAQ Adult_09_Brain  iBAQ Adult_10_Brain  iBAQ Adult_11_Brain  \\\n",
      "0            29.194339            29.104628            29.192648   \n",
      "1            29.860161            29.973369            29.829833   \n",
      "2            28.882223            28.813767            28.967261   \n",
      "3            30.126402            29.868505            30.083839   \n",
      "4            28.541534            28.305012            28.342141   \n",
      "\n",
      "   iBAQ Adult_12_Brain  iBAQ Adult_07_Heart  iBAQ Adult_08_Heart  \\\n",
      "0            29.149014            27.154743            27.582419   \n",
      "1            29.899412            29.098229            28.660110   \n",
      "2            28.837046            25.965725            26.029053   \n",
      "3            29.978137            28.312536            28.362037   \n",
      "4            28.418009            26.779122            26.863021   \n",
      "\n",
      "   iBAQ Adult_09_Heart         ...          iBAQ Adult_06_Liver  \\\n",
      "0            27.451654         ...                    26.660100   \n",
      "1            28.630875         ...                    27.690679   \n",
      "2            26.019648         ...                    25.139250   \n",
      "3            28.144499         ...                    27.231414   \n",
      "4            26.563870         ...                    26.189453   \n",
      "\n",
      "   iBAQ Adult_07_Liver  iBAQ Adult_08_Liver  iBAQ Adult_09_Liver  \\\n",
      "0            26.148780            26.697213            26.991464   \n",
      "1            27.868337            28.070885            27.919769   \n",
      "2            24.751595            25.294242            25.180824   \n",
      "3            27.135472            27.413404            27.320516   \n",
      "4            25.965913            25.571355            25.867638   \n",
      "\n",
      "   iBAQ Adult_07_Lung  iBAQ Adult_08_Lung  iBAQ Adult_09_Lung  \\\n",
      "0           28.854903           28.905764           28.778552   \n",
      "1           29.101379           29.085984           29.314853   \n",
      "2           27.215532           27.130005           27.219581   \n",
      "3           27.657743           28.015049           27.760108   \n",
      "4           27.698800           27.715981           27.700782   \n",
      "\n",
      "   iBAQ Adult_10_Lung  iBAQ Adult_11_Lung  iBAQ Adult_12_Lung  \n",
      "0           28.667623           28.625906           28.644704  \n",
      "1           29.220096           29.138074           29.207950  \n",
      "2           26.925858           27.046783           27.245973  \n",
      "3           27.745042           27.622374           27.596048  \n",
      "4           27.638797           27.622081           27.894200  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "datafile = \"D:\\proteinGroups.txt\"\n",
    "sample_groups = ['Brain', 'Heart', 'Kidney', 'Liver', 'Lung']\n",
    "base_dir = 'D:\\\\Images\\\\PipelineTest\\\\'\n",
    "\n",
    "df = mq_pipeline(datafile, sample_groups, base_dir)\n",
    "print(df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO \n",
    "* Dynamically determine column indices for organ groups, size of groups; order columns\n",
    "* Take argument to choose iBAQ or LFQ? Or just do both...If arg = iBAQ: df = iBAQ_df else: df = LFQ_df\n",
    "* Write images out to file - take argument for specific dataset name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
