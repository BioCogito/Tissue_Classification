{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Classification_Utils as cu\n",
    "import MaxQuant_Postprocessing_Functions as mq\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "  table {margin-left: 0 !important;}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "  table {margin-left: 0 !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify mouse tissue using protein and peptide abundance data\n",
    "* Use proteinGroups.txt or peptides.txt outputted from MaxQuant\n",
    "* SVC variations\n",
    "* K neighbors\n",
    "* Decision tree\n",
    "* Logistic Regression\n",
    "* Naive Bayes (Gaussian and Multinomial)\n",
    "* Gradient Boosting\n",
    "\n",
    "** With train-test split, test_size = 0.4:**\n",
    "\n",
    "Algorithm | Accuracy Score\n",
    ":-----:|:-----:\n",
    "SVC kernel = linear | 1.0\n",
    "LinearSVC | 0.75 \\*\n",
    "SVC kernel = rbf | 0.167\n",
    "SVC kernel = poly | 1.0\n",
    "KNN | 1.0\n",
    "Decision Tree | 0.67 \\*\n",
    "\n",
    "\\* varies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PLOT_PCA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean mouse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = \"D:\\proteinGroups.txt\"\n",
    "\n",
    "df = mq.load_df(file)\n",
    "df = mq.clean_weakly_identified(df)\n",
    "df = mq.remove_dup_proteinIDs(df)\n",
    "\n",
    "iBAQ_df = mq.slice_by_column(df, 'protein', 'iBAQ ')\n",
    "\n",
    "# Rename columns so that all instances \"before\" string are replaced with \"after\" string\n",
    "def rename_columns(df, before, after):\n",
    "    columns = df.columns.values.tolist()\n",
    "    new_columns = []\n",
    "    for column in columns:\n",
    "        new_column = re.sub(before, after, column)\n",
    "        new_columns.append(new_column)\n",
    "        \n",
    "    return new_columns\n",
    "\n",
    "iBAQ_df.columns = rename_columns(iBAQ_df, 'Adult', 'Mouse')\n",
    "\n",
    "groups = ['Brain', 'Heart', 'Kidney', 'Liver', 'Lung']\n",
    "organ_columns = {} # 'Liver': ['iBAQ 04_Liver', 'iBAQ 05_Liver', ...]\n",
    "organ_counts = {} # 'Liver': \n",
    "    \n",
    "iBAQ_df = mq.filter_low_observed(iBAQ_df, groups, organ_columns, organ_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to replace low abundance values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Replace low abundance values with 0\n",
    "def replace_with_zero(x):\n",
    "    min_val = 7\n",
    "    \n",
    "    if type(x) is str:\n",
    "        return x\n",
    "    \n",
    "    elif pd.isnull(x) or x < min_val:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "#iBAQ_df.applymap(replace_with_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data and impute missing values with (data frame minimum/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kush494\\Documents\\Proteomics_Data_Processing\\MaxQuant_Postprocessing_Functions.py:151: RuntimeWarning: divide by zero encountered in log2\n",
      "  df.iloc[:,1:] = np.log2(df.iloc[:,1:])\n"
     ]
    }
   ],
   "source": [
    "mq.log2_normalize(iBAQ_df)\n",
    "mq.median_normalize(iBAQ_df)\n",
    "\n",
    "iBAQ_df['Majority protein IDs'] = iBAQ_df['Majority protein IDs'].str[:-6] # strip off '_Mouse'\n",
    "iBAQ_df.set_index('Majority protein IDs', inplace = True)\n",
    "\n",
    "df_min = iBAQ_df.min().min()\n",
    "impute_val = df_min/2\n",
    "iBAQ_df = iBAQ_df.fillna(impute_val)\n",
    "\n",
    "#iBAQ_df = mq.impute_missing(iBAQ_df) TODO change method to work whether df is indexed or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map each column name to a corresponding label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Args: \n",
    "    df (dataframe)\n",
    "    columns (list of strings): list of all column names in df\n",
    "    organ_to_columns (dict): mapping of each organ to its column names {str: list of str}\n",
    "    \n",
    "Returns: \n",
    "    List of strings representing the labels for each dataframe column\n",
    "\"\"\"\n",
    "def get_labels(df, columns, organ_to_columns):\n",
    "    labels = []\n",
    "\n",
    "    for column in columns:\n",
    "        key = next(key for key, value in organ_to_columns.items() if column in value)\n",
    "        labels.append(key)\n",
    "        \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iBAQ Mouse_07_Brain', 'iBAQ Mouse_08_Brain', 'iBAQ Mouse_09_Brain', 'iBAQ Mouse_10_Brain', 'iBAQ Mouse_11_Brain', 'iBAQ Mouse_12_Brain', 'iBAQ Mouse_07_Heart', 'iBAQ Mouse_08_Heart', 'iBAQ Mouse_09_Heart', 'iBAQ Mouse_10_Heart', 'iBAQ Mouse_11_Heart', 'iBAQ Mouse_12_Heart', 'iBAQ Mouse_07_Kidney', 'iBAQ Mouse_08_Kidney', 'iBAQ Mouse_09_Kidney', 'iBAQ Mouse_10_Kidney', 'iBAQ Mouse_11_Kidney', 'iBAQ Mouse_12_Kidney', 'iBAQ Mouse_04_Liver', 'iBAQ Mouse_05_Liver', 'iBAQ Mouse_06_Liver', 'iBAQ Mouse_07_Liver', 'iBAQ Mouse_08_Liver', 'iBAQ Mouse_09_Liver', 'iBAQ Mouse_07_Lung', 'iBAQ Mouse_08_Lung', 'iBAQ Mouse_09_Lung', 'iBAQ Mouse_10_Lung', 'iBAQ Mouse_11_Lung', 'iBAQ Mouse_12_Lung']\n",
      "['Brain', 'Brain', 'Brain', 'Brain', 'Brain', 'Brain', 'Heart', 'Heart', 'Heart', 'Heart', 'Heart', 'Heart', 'Kidney', 'Kidney', 'Kidney', 'Kidney', 'Kidney', 'Kidney', 'Liver', 'Liver', 'Liver', 'Liver', 'Liver', 'Liver', 'Lung', 'Lung', 'Lung', 'Lung', 'Lung', 'Lung']\n"
     ]
    }
   ],
   "source": [
    "iBAQ_df = iBAQ_df[organ_columns['Brain'] + organ_columns['Heart'] + organ_columns['Kidney'] + organ_columns['Liver'] + organ_columns['Lung']]\n",
    "\n",
    "columns = iBAQ_df.columns.values.tolist()\n",
    "col_labels = get_labels(iBAQ_df, columns, organ_columns)\n",
    "\n",
    "print(columns)\n",
    "print(col_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data and labels into test and train groups\n",
    "* X_train and X_test represent raw subsets of the original dataframe\n",
    "* X_t_train and X_t_test represent data transformed by PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 4399)\n",
      "(15, 4399)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import cross_validation\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Transpose df so that proteins are columns (components)\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(iBAQ_df.T, col_labels, test_size=0.5, random_state=0, stratify=col_labels)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold all data to simulate lower-quality data with fewer attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "metadata": {},
   "outputs": [],
   "source": [
    "iBAQ_t = iBAQ_df.T\n",
    "\n",
    "iBAQ_oneprotein_df = iBAQ_t.drop(X_test.columns[list(range(num_rows-1))], axis=1)\n",
    "iBAQ_sixteenth_percent_df = iBAQ_t.drop(X_test.columns[list(range(math.floor(num_rows*(1599/1600))))], axis=1)\n",
    "iBAQ_eighthpercent_df = iBAQ_t.drop(X_test.columns[list(range(math.floor(num_rows*(799/800))))], axis=1)\n",
    "iBAQ_quarterpercent_df = iBAQ_t.drop(X_test.columns[list(range(math.floor(num_rows*(399/400))))], axis=1)\n",
    "iBAQ_halfpercent_df = iBAQ_t.drop(X_test.columns[list(range(math.floor(num_rows*(199/200))))], axis=1)\n",
    "iBAQ_onepercent_df = iBAQ_t.drop(X_test.columns[list(range(math.floor(num_rows*(99/100))))], axis=1)\n",
    "iBAQ_twentieth_df = iBAQ_t.drop(X_test.columns[list(range(math.floor(num_rows*(95/100))))], axis=1)\n",
    "iBAQ_tenth_df = iBAQ_t.drop(X_test.columns[list(range(math.floor(num_rows*(9/10))))], axis=1)\n",
    "iBAQ_quarter_df = iBAQ_t.drop(X_test.columns[list(range(math.floor(num_rows*(3/4))))], axis=1)\n",
    "iBAQ_half_df = iBAQ_t.drop(X_test.columns[list(range(num_rows//2))], axis=1)\n",
    "iBAQ_three_quarters_df = iBAQ_t.drop(X_test.columns[list(range(num_rows//4))], axis=1)\n",
    "iBAQ_nine_tenths_df = iBAQ_t.drop(X_test.columns[list(range(num_rows//10))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 3)"
      ]
     },
     "execution_count": 1099,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iBAQ_df = iBAQ_sixteenth_percent_df\n",
    "iBAQ_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold Test data to simulate lower-quality data with fewer attributes; classification on mixed-quality data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2200, 30]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-227-a044c49cb174>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m### Pairwise ratios\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mkbest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_k_best_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miBAQ_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mpairwise_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairwise_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkbest_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Proteomics_Data_Processing\\Classifiers\\Classification_Utils.py\u001b[0m in \u001b[0;36mkeep_k_best_features\u001b[1;34m(df, labels, k)\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[0mselect_k_best_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m     \u001b[0mkbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_k_best_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m     \u001b[0mfit_transformed_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_k_best_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \"\"\"\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 204\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2200, 30]"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "import math\n",
    "\n",
    "num_rows = X_test.shape[1]\n",
    "\n",
    "twentieth_df = X_test.drop(X_test.columns[list(range(math.floor(num_rows*(95/100))))], axis=1)\n",
    "tenth_df = X_test.drop(X_test.columns[list(range(math.floor(num_rows*(9/10))))], axis=1)\n",
    "quarter_df = X_test.drop(X_test.columns[list(range(math.floor(num_rows*(3/4))))], axis=1)\n",
    "half_df = X_test.drop(X_test.columns[list(range(num_rows//2))], axis=1)\n",
    "three_quarters_df = X_test.drop(X_test.columns[list(range(num_rows//4))], axis=1)\n",
    "nine_tenths_df = X_test.drop(X_test.columns[list(range(num_rows//10))], axis=1)\n",
    "\n",
    "### By Percentile\n",
    "#X_test = SelectPercentile(percentile=10).fit_transform(X_test, y_test)\n",
    "\n",
    "### Randomly\n",
    "X_test = twentieth_df\n",
    "\n",
    "### Pairwise ratios\n",
    "kbest_df = cu.keep_k_best_features(iBAQ_df, col_labels, 50)\n",
    "pairwise_df = cu.pairwise_transform(kbest_df)\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tenth_df.shape)\n",
    "print(quarter_df.shape)\n",
    "print(half_df.shape)\n",
    "print(three_quarters_df.shape)\n",
    "print(nine_tenths_df.shape)\n",
    "print(num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create \"filler\" array containing the imputed value to stand in for attributes that have been removed\n",
    "\n",
    "total_attributes = X_train.shape[1]\n",
    "\n",
    "filler_array = np.full((X_test.shape[0], total_attributes - X_test.shape[1]), impute_val)\n",
    "filler_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combine filler array to reduced X_test to match training data shape for classification\n",
    "\n",
    "X_test = np.concatenate((X_test, filler_array), axis=1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold portion of training data to simulate training on a mix of high- and low- quality data. Test with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine X_test back with X_train\n",
    "\n",
    "thresholded_df = np.concatenate((X_train.T, X_test.T), axis=1)\n",
    "\n",
    "thresholded_labels = y_train + y_test\n",
    "thresholded_df = pd.DataFrame(thresholded_df, columns = thresholded_labels)\n",
    "\n",
    "thresholded_df.set_index(iBAQ_df.index, inplace=True)\n",
    "\n",
    "print(thresholded_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw PCA plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if PLOT_PCA:\n",
    "    base_dir = 'D:\\\\Images\\\\Mouse_Data_Thresholding\\\\Original_'\n",
    "    color_mapping = mq.map_colors(groups, organ_columns)\n",
    "    columns = iBAQ_df.columns.values.tolist()\n",
    "\n",
    "    whole_df_pca, whole_df_pca_data = mq.do_pca(iBAQ_df.copy(), 'protein', scale=False)\n",
    "    per_var, labels = mq.make_scree_plot(whole_df_pca, base_dir)\n",
    "    mq.draw_pca_graph(columns, whole_df_pca_data, base_dir, color_mapping, per_var, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "#X_train = preprocessing.scale(X_train)\n",
    "pca.fit(X_train)\n",
    "X_t_train = pca.transform(X_train)\n",
    "X_t_test = pca.transform(X_test)\n",
    "\n",
    "print(X_t_train.shape)\n",
    "print(X_t_test.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mq.top_n_loading_scores(pca, iBAQ_df, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC and Variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Basic SVC Classification with train-test split\n",
    "#\n",
    "#########################\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = SVC(C=1)\n",
    "clf.fit(X_t_train, y_train)\n",
    "y_pred = clf.predict(X_t_test)\n",
    "\n",
    "print('score', accuracy_score(y_pred, y_test))\n",
    "print('pred label', clf.predict(X_t_test))\n",
    "print('actual', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8  0.7  0.8  0.8]\n",
      "Accuracy: 0.77 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#\n",
    "# Basic SVC Classification with cross-validation\n",
    "#\n",
    "#########################\n",
    "clf2 = SVC(C=1)\n",
    "scores = cross_val_score(clf2, iBAQ_df, col_labels, cv=4)                 # Whole df\n",
    "#scores = cross_val_score(clf2, thresholded_df.T, thresholded_labels, cv=4)  # Thresholded\n",
    "#scores = cross_val_score(clf2, pairwise_df.T, col_labels, cv=4)              # Pairwise\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#########################\n",
    "#\n",
    "# SVC variations with train-test split\n",
    "#\n",
    "#########################\n",
    "\n",
    "def try_SVC_models(X_train, y_train, X_test, y_test):\n",
    "    C = 1.0  # SVM regularization parameter\n",
    "    models = (SVC(kernel='linear', C=C),\n",
    "              LinearSVC(C=C),\n",
    "              SVC(kernel='rbf', gamma=0.7, C=C),\n",
    "              SVC(kernel='poly', degree=3, C=C))\n",
    "\n",
    "    # Fit all the models\n",
    "    models = (clf.fit(X_train, y_train) for clf in models)\n",
    "\n",
    "    for model in models:\n",
    "        model_y_pred = model.predict(X_test)\n",
    "        print('\\n*** Model: ', model, '\\n')\n",
    "        print('score', accuracy_score(model_y_pred, y_test))\n",
    "        print('pred label', model_y_pred)\n",
    "        print('actual', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_SVC_models(X_t_train, y_train, X_t_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_t_train, y_train)\n",
    "y_pred = knn.predict(X_t_test)\n",
    "\n",
    "print('score', accuracy_score(y_pred, y_test))\n",
    "print('pred', y_pred)\n",
    "print('actual', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5  0.7  0.6  0.4]\n",
      "Accuracy: 0.55 (+/- 0.22)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 1108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn2 = KNeighborsClassifier()\n",
    "scores = cross_val_score(knn2, iBAQ_df, col_labels, cv=4)\n",
    "#scores = cross_val_score(knn2, thresholded_df.T, thresholded_labels, cv=4)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "knn2.fit(iBAQ_df, col_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SKLearn Pipeline: Train-test split, PCA transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe = Pipeline([('scaling', StandardScaler()),\n",
    "                 ('pca', PCA()),\n",
    "                 ('knn', KNeighborsClassifier())])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "#print(cross_val_score(pipe, iBAQ_df.T, col_labels))\n",
    "\n",
    "pipe_pred = pipe.predict(X_test)\n",
    "print('score', accuracy_score(pipe_pred, y_test))\n",
    "print('pred', pipe_pred)\n",
    "print('actual', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_clf = tree.DecisionTreeClassifier()\n",
    "decision_tree_clf = decision_tree_clf.fit(X_t_train, y_train)\n",
    "dt_pred = decision_tree_clf.predict(X_t_test)\n",
    "\n",
    "print('score', accuracy_score(dt_pred, y_test))\n",
    "print('pred', dt_pred)\n",
    "print('actual', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8  0.8  0.8  0.8]\n",
      "Accuracy: 0.80 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "dt2 = tree.DecisionTreeClassifier()\n",
    "scores= cross_val_score(dt2, iBAQ_df, col_labels, cv=4)\n",
    "#scores = cross_val_score(dt2, thresholded_df.T, thresholded_labels, cv=4)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [ 0.5  0.6  0.6  0.4]\n",
      "accuracy: 0.53 (+/- 0.17)\n"
     ]
    }
   ],
   "source": [
    "lr = cu.logistic_regression_model_crossval(iBAQ_df, col_labels, 4)\n",
    "#lr = cu.logistic_regression_model_crossval(thresholded_df.T, thresholded_labels, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb = gnb.fit(X_t_train, y_train)\n",
    "gnb_pred = gnb.predict(X_t_test)\n",
    "\n",
    "print('score', accuracy_score(gnb_pred, y_test))\n",
    "print('pred', gnb_pred)\n",
    "print('actual', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [ 0.9  0.6  0.8  0.8]\n",
      "accuracy: 0.77 (+/- 0.22)\n"
     ]
    }
   ],
   "source": [
    "gnb2 = cu.bayes_gaussian_model_crossval(iBAQ_df, col_labels, 4)\n",
    "#gnb2 = cu.bayes_gaussian_model_crossval(thresholded_df.T, thresholded_labels, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnb = cu.bayes_multinomial_model_crossval(thresholded_df.T, thresholded_labels, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = cu.gradient_boosting_crossval(thresholded_df.T, thresholded_labels, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbc_grid = cu.gbc_grid_search(4, 1)\n",
    "\n",
    "gbc_grid.fit(thresholded_df.T, thresholded_labels)\n",
    "\n",
    "print('Best Gradient Boosting parameters:\\n', gbc_grid.best_params_)\n",
    "print('\\nBest Cross-Validation score:\\n', gbc_grid.best_score_)\n",
    "#print('\\nBest F1-score:\\n', rf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp_grid = cu.mlp_grid_search(4, 1)\n",
    "\n",
    "mlp_grid.fit(thresholded_df.T, thresholded_labels)\n",
    "\n",
    "print('Best MLPClassifier parameters:\\n', mlp_grid.best_params_)\n",
    "print('\\nBest Cross-Validation score:\\n', mlp_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify using Peptide Data\n",
    "* Use peptides.txt output from MaxQuant\n",
    "* SVC varations\n",
    "* K nearest neighbors\n",
    "* Decision tree\n",
    "\n",
    "** With train-test split, test_size = 0.4: **\n",
    "\n",
    "Algorithm | Accuracy Score\n",
    ":-----:|:-----:\n",
    "SVC kernel = linear | 1.0\n",
    "LinearSVC | 1.0 \\*\n",
    "SVC kernel = rbf | 0.167\n",
    "SVC kernel = poly | 0.917\n",
    "KNN | 1.0\n",
    "Decision Tree | 1.0 \\*\n",
    "\n",
    "\\* varies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean peptide data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_file = \"D:\\peptides.txt\"\n",
    "\n",
    "peptide_df = mq.load_df(peptide_file)\n",
    "peptide_df = mq.slice_by_column(peptide_df, 'peptide', 'LFQ')\n",
    "peptide_df.columns = rename_columns(peptide_df, 'Adult', 'Mouse')\n",
    "\n",
    "peptide_organ_columns = {}\n",
    "peptide_organ_counts = {}\n",
    "peptide_df = mq.filter_low_observed(peptide_df, groups, peptide_organ_columns, peptide_organ_counts)\n",
    "mq.log2_normalize(peptide_df)\n",
    "mq.median_normalize(peptide_df)\n",
    "\n",
    "peptide_df = peptide_df.replace(r'\\n','', regex=True)\n",
    "peptide_df.set_index('Sequence', inplace = True)\n",
    "peptide_df = mq.impute_missing(peptide_df)\n",
    "\n",
    "peptide_columns = peptide_df.columns.values.tolist()\n",
    "peptide_labels = get_labels(peptide_df, peptide_columns, peptide_organ_columns)\n",
    "print(peptide_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data and labels into test and train groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_peptide_data = preprocessing.scale(peptide_df.T)\n",
    "\n",
    "### Randomly split:\n",
    "peptide_X_train, peptide_X_test, peptide_y_train, peptide_y_test = cross_validation.train_test_split(peptide_df.T, peptide_labels, test_size=0.4, random_state=0, stratify=peptide_labels)\n",
    "\n",
    "peptide_pca = PCA(n_components=4)\n",
    "peptide_pca.fit(peptide_X_train)\n",
    "peptide_X_t_train = peptide_pca.transform(peptide_X_train)\n",
    "peptide_X_t_test = peptide_pca.transform(peptide_X_test)\n",
    "\n",
    "print(peptide_X_t_train.shape)\n",
    "print(peptide_X_t_test.shape)\n",
    "print(peptide_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw PCA plots for peptide data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "peptide_dir = base_dir + 'Mouse_Peptide_'\n",
    "peptide_color_mapping = mq.map_colors(groups, peptide_organ_columns)\n",
    "columns = peptide_df.columns.values.tolist()\n",
    "\n",
    "peptide_pca, peptide_pca_data = mq.do_pca(peptide_df.copy(), scale=False)\n",
    "peptide_per_var, peptide_labels = mq.make_scree_plot(peptide_pca, peptide_dir)\n",
    "mq.draw_pca_graph(columns, peptide_pca_data, peptide_dir, peptide_color_mapping, peptide_per_var, peptide_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_clf = SVC()\n",
    "peptide_clf.fit(peptide_X_t_train, peptide_y_train)\n",
    "peptide_y_pred = peptide_clf.predict(peptide_X_t_test)\n",
    "\n",
    "print('score', accuracy_score(peptide_y_pred, peptide_y_test))\n",
    "print('pred label', peptide_y_pred)\n",
    "print('actual', peptide_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_SVC_models(peptide_X_t_train, peptide_y_train, peptide_X_t_test, peptide_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_knn = KNeighborsClassifier()\n",
    "peptide_knn.fit(peptide_X_t_train, peptide_y_train)\n",
    "peptide_y_pred = peptide_knn.predict(peptide_X_t_test)\n",
    "\n",
    "print('score', accuracy_score(peptide_y_pred, peptide_y_test))\n",
    "print('pred', peptide_y_pred)\n",
    "print('actual', peptide_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_dt_clf = tree.DecisionTreeClassifier()\n",
    "peptide_dt_clf = peptide_dt_clf.fit(peptide_X_t_train, peptide_y_train)\n",
    "peptide_dt_pred = peptide_dt_clf.predict(peptide_X_t_test)\n",
    "\n",
    "print('score', accuracy_score(peptide_dt_pred, peptide_y_test))\n",
    "print('pred', peptide_dt_pred)\n",
    "print('actual', peptide_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Confusion matrix shows which labels are being misclassified\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(peptide_y_test, peptide_dt_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=groups,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=groups, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
