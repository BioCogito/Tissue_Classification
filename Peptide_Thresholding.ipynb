{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using unlabelled, unfractionated datasets obtained from QExact and VOrbi instruments\n",
    "* Datasets were searched against H_sapiens_Uniprot_SPROT_2017-04-12, Tryp_Pig_Bov sequence files using MSGFPlus\n",
    "* Combined results with MASIC results (q <= 0.01) to get quantitation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Classification_Utils as cu\n",
    "import math\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and combine data from all tissues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('FullPeptideQuant.txt', sep='\\t', index_col='Peptide')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map each column to a corresponding label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissues = ['Blood_Plasma', 'Blood_Serum', 'CSF', 'Liver', 'Monocyte', 'Ovary', 'Pancreas', 'Substantia_Nigra', 'Temporal_Lobe']\n",
    " \n",
    "tissues_to_columns = cu.map_tissues_to_columns(df, tissues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_names = df.columns.values.tolist()\n",
    "labels = cu.get_labels(column_names, tissues_to_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df, test_df, train_labels, test_labels = train_test_split(\n",
    "    df.T, labels, test_size=0.30,# 30% of the data held out in test set\n",
    "    random_state=0,    # Setting random_state ensures the same train/test split occurs each time this is run\n",
    "    stratify=labels)   # Maintain relative ratio of samples from each tissue\n",
    "\n",
    "original_train_df = train_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Train Data by Reducing Peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keep_percentile_peptides(df, labels, tissues, percentile, impute_val):\n",
    "    df = df.T\n",
    "    tissue_dfs = []\n",
    "    \n",
    "    for tissue in tissues:\n",
    "        cols_to_drop = [col for col in df.columns.values if not col.startswith(tissue)]\n",
    "        tissue_df = df.drop(cols_to_drop, axis=1)\n",
    "        \n",
    "        ### Drop rows with nothing observed\n",
    "        tissue_df.replace(impute_val, np.nan, inplace=True)\n",
    "        tissue_df.dropna(axis=0, how='all', inplace=True)\n",
    "        tissue_df.replace(np.nan, impute_val, inplace=True)\n",
    "        \n",
    "        peptide_mean_abundances = tissue_df.mean(axis=1) # pandas series\n",
    "\n",
    "        # sort by average abundance value, drop below threshold\n",
    "        peptide_mean_abundances.sort_values(ascending=False, inplace=True)\n",
    "        num_peptides_to_keep = math.ceil(len(peptide_mean_abundances) * percentile/100)\n",
    "        peptides_to_drop = peptide_mean_abundances[num_peptides_to_keep:].index.values\n",
    "        \n",
    "        print(tissue_df.shape[0], len(peptides_to_drop))\n",
    "        \n",
    "        tissue_df.drop(peptides_to_drop, axis=0, inplace=True)\n",
    "        \n",
    "        tissue_dfs.append(tissue_df)\n",
    "        \n",
    "    # join dataframes\n",
    "    combined_df = pd.DataFrame()\n",
    "    for next_df in tissue_dfs:\n",
    "        combined_df = combined_df.join(next_df, how='outer')\n",
    "    \n",
    "    combined_df.replace(np.nan, impute_val, inplace=True)\n",
    "        \n",
    "    return combined_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imputed_val = train_df.mode().iloc[0, 0]\n",
    "\n",
    "percentile_to_keep = 0.0007\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df = keep_percentile_peptides(train_df, train_labels, tissues, percentile_to_keep, imputed_val)\n",
    "print(train_df.shape)\n",
    "\n",
    "features_to_keep = train_df.columns.values.tolist()\n",
    "\n",
    "column_names = train_df.index.values.tolist()\n",
    "train_labels = cu.get_labels(column_names, tissues_to_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifiers on the reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "lr = LogisticRegression(random_state=0)\n",
    "mnb = MultinomialNB()\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "svc = SVC(kernel='linear', random_state=0)\n",
    "gbc = GradientBoostingClassifier(random_state=0)\n",
    "gnb = GaussianNB()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "models = [lr, mnb, rf, svc, gbc, gnb, knn]\n",
    "\n",
    "model_names = ['Logistic Regression', 'Multinomial Naive Bayes', 'Random Forest', 'SVC', \n",
    "               'Gradient Boosting', 'Gaussian Naive Bayes', 'K-Nearest Neighbors']\n",
    "\n",
    "for model in models:\n",
    "    model.fit(train_df, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data features (peptides) must match training data features exactly\n",
    "# So we only keep the peptides still present in the training data after peptide reduction\n",
    "\n",
    "print(test_df.shape)\n",
    "test_df = test_df[features_to_keep]\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use models from notebook to predict new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_pred = lr.predict(test_df)\n",
    "lr_result = lr.score(test_df, test_labels)\n",
    "\n",
    "mnb_pred = mnb.predict(test_df)\n",
    "mnb_result = mnb.score(test_df, test_labels)\n",
    "\n",
    "rf_pred = rf.predict(test_df)\n",
    "rf_result = rf.score(test_df, test_labels)\n",
    "\n",
    "svc_pred = svc.predict(test_df)\n",
    "svc_result = svc.score(test_df, test_labels)\n",
    "\n",
    "knn_pred = knn.predict(test_df)\n",
    "knn_result = knn.score(test_df, test_labels)\n",
    "\n",
    "gnb_pred = gnb.predict(test_df)\n",
    "gnb_result = gnb.score(test_df, test_labels)\n",
    "\n",
    "gbc_pred = gbc.predict(test_df)\n",
    "gbc_result = gbc.score(test_df, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svc_result)\n",
    "print(knn_result)\n",
    "print(gnb_result)\n",
    "print(gbc_result)\n",
    "print(mnb_result)\n",
    "print(lr_result)\n",
    "print(rf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm_labels = list(set(knn_pred.tolist() + test_labels))\n",
    "\n",
    "cu.show_confusion_matrices(test_labels, knn_pred, cm_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
